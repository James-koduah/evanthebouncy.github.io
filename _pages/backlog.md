---
title:
layout: default
permalink: /backlog/
published: true
---

# Backlog of Ideas

the content in /thoughts/ are more public things that I would say and feel confident would be good. 
This is more for myself, poorly worded and isn't really "validated". Hence this is backlog.

### 2023-04-01 research ideas with daniel friend

it seems easier for open source community to catch up in code models as opposed to open ended dialogue in a race against openAI. this is useful because code models have the most "utility" for the things I care about.

RL is compiled search -- taking a multi-step action sequence and compressing it down to 1 step. That view is fairly widely accepted. However, what is not widely appreciated is that even for alphaZero, it _still_ has to perform search and compute at inference time, playing many games over to decide the best move. This _strongly_ implies that reward model plus search is better than memorizing the solution for each problem -- that the _process_ of doing a search is more efficient (literally, cram-able into a NN sense) than the _solution_ of memorizing a right move at every board state.

### 2023-04-02 overall development stuff

We know accomplishment is the best thing for external validation, for people who have no time to judge if "you're worth it". Internal validation can be build with time between collaborators, but external one the best is through accomplishment. i.e. if I can say "I've built a dataset worth of 1mil dollars", that would be cool.

Thus in collaboration one very important consideration is to "actually get stuff done". If you can accomplish a goal in a collaboration, everyone is happy.

Sometimes the best way to benefit your collaborator is not to talk and talk, but to listen. Sometimes it is paying instead of rewarding when you're listening. For people with strong personality and want to "emit ideas" (like myself), they want listeners. I need to be better listeners, this is good way to help.

The best way to collaborate is to _just ask them_ what they need help with. If you can give people what they actually need (i.e. they can tell you ffs), you're being helpful. You should just ask, don't guess -- I'm terrible at guessing what people need. I should just ask.

### 2023-03-29 ideas

The following are technologies compliant with _existing_ capabilities. These are not research ideas, but can spin into start-ups if someone's willing.

Web will change. Ads as we know it will dissapear. There will first be an APP where it'll render the web in sandbox mode, and then re-render it for you, ignoring all the parts that are not of interests. You will have in front of your face a "personalized renderer" that interface you to the "information web", that actively filter and curate information. Once this personalized renderer becomes commonplace, most websites will devolve to just ChatAPIs, like how ChatGPT is already thinking how it should be, and provide only functionalities, sending easily digestable jsons -- you render them however you want.

One immediate move (as of today) in response to ChatGPT is the creation of a shell, or public persona. Multiple can be created. It can ingest data that you generated, and can act (chat, etc) on your behalf. So interactions of buying grocery, booking flights, etc, will be done with this shell.

Observation: Humans did not evolve well to socialize with so many different other humans. We are not designed for it. We prefer few interactions, smaller groups. Most of the socialization nowaday are _forced and unnatural_ and will have a strong incentive to be optimized away. Thus day to day social interactions, of the mundane, unpleasurable kind, will reduce. That will be done with shells.

Observation: There are way too much information available, no human can ingest them all. We badly need a curator of sorts.

Observation (combining the previous 2): Society is best run by statistical averages. Humans are fundamentally novelty seeking and work horribly with averages -- we're unfit to govern ourselves in a sense. Society should be organized by AI, which cannot be malicious as it can only reason in averages, and individual humans will focus on pushing the boundaries of knowledge/civilization. Statistical methods that train these AI will be incapable of becoming malicious in a "sUdDeNlY iT's EvIl!" fashion, as it is an average of opinions, capable of speaking on our (our = humanity) behalf fairly.

AI safety thus is primarily about whom and what thoughts can be uploaded online, to prevent these statistical learners from learning a "skewed" worldview. Perhaps this process itself is the new "review" critiera in a academic conference sense. If your work pass the review, it gets to be uploaded into the collective. I have no idea how this will work in a good way.

Observation: The best communicative system is human body, where cells work together in highly complex and capable ways that we have _no clue_ how it work tbh. As society progress we'll have to improve our communication. Bad news is that current communication, i.e. going to work, mandatory zoom bullshit meetings, booking calendar so both can be there, is HORRIBLE. Good news is that we've only been doing the communication problem for what, 2000 years as a civilization? There's a room for improvement, lots of room.

There will be a new social media set up where all actors are "shells". You can have a new kind of market place of buyer/seller, but all shells, and dating, and scientists. The shells will generate, curate, and relay information to you in a nice form that you can digest. 

data format is pain. we massage data from one form to another all the freaking time. this reasults in a lot of training data for transformation of data between formats. thus different formats will go away because it killed itself.