---
title:
layout: default
permalink: /thoughts/
published: true
---

### Thoughts

Here are scattered thoughts that I think are cool.
They range from ideas, quotes from others, observations, a dream I had, opinions. Think of these as passages found in fortune cookies. Treat with open minds and cautions.

In the near future, a LLM will be able to summarize this body of text, and you'd be able to interact with it through a natural interface, which can retrieve the right quotes from this text document. 

Written in no particular order, but recent thoughts tends to be on top.

----

[x] a presentation could be more like a poem, with more empty negative spaces, and let the audience fill in with their own imagination and excitement. however, what is being written has to be highly defensible and solid.

[x] ask yourself everyday
    - what is my high lvl goal ?
    - what should I do to meet it?
    - keep doing these two and become free of external validations

[x] research is the shortest path to the research question

[x] asking for critiques on presentation / paper, ask both:
    - be cynical and brutal, why would you reject it ?
    - be optimistic and excited, how would you sell it ?

[x] judy fan on how to organize research
    - organize it around sub-goals that you want to hit, an "attack path"

[x] daniel ritche on experiments
    - don't play wack-a-mole with experiments

[x] armando on paper writing
    - every paper is written around a singular idea or concept.

[x] daniel fried on paper writing
    - write it so the setting is more general, and double down if they ask about it (on writing paper with multiple domains)
    - every sentence you re-write, ask yourself : rewrite this sentence to maximize the chance of paper getting accepted
    - make the claim in the abstract / intro as strong and general as possible
    - if you can have a paper where reader can appreciate without understanding technicals, that's how you get a W on inexperienced reviewers
    - minimize confusion --- don't confuse the reader
    - maximize impact --- never undersell it

[x] beilei : 0 point in speaking to prove ur right. 100 point for speaking to accomplish a mutual goal. ppl are not stupid, they know which kind of speaking ur doing right away.

[x] josh : be polite with prior works, "I'm not trying to take away from what's being build, they are impressive, BUT ... "

[x] josh : be conservative with the claims, and upfront with the limitations. I am confident in what I am presenting as a way to get there, but we're not there. Long term road-map, Short term road map.

[x] max : what's the thing a reader should learn from the slide? if they don't learn anything new, remove the slide.

[x] do not use subjective words like "X is important" in writing. that is NOT for you to say, that is for the reader to decide. state the facts, e.g. "X is common".

[x] the value of writing is not to share with the world what's in your head, but to convince they reader how they should see the world differently.

[x] alex / karl : a collaborator should bring something new to the table, they should be able to teach you something. otherwise arnt you working alone ?

[x] josh : give it time, be patient. you'll grow into the researcher you're meant to be.

[x] josh : it is good to frame yourself as someone who does code-generation, but something more interesting on top.

[x] josh : a bad way to do research is "wouldn't it be cool to do X" --- that is a big waste of time. the right way to do research is question driven. what is the research question?

[x] it is better to be firm, and expect your collaborator the same level of standard as yourself.

[x] more important than being nice to students, be fair to students; show the same level of kindness to all students.

[x] it is good to have paper / figure reviews internally in the group to have a standard of the group.

[x] gabe grand : we'll call your figure "the egg man"

[x] old ideas last longer than new ideas into the future. it is often good idea to re-connect with old ideas

[x] in research on a new, challenging area, such as building algorithms that follow human instructions, you want to identify balloon monster problems -- challenging problems that goes pop if you push it slightly with this new technique. this way you can communicate what you're doing is valuable to other people, without sinking too much time into making your research fully fledged.

[x] jiajun : on research, do not waste time. when stuck, identify the key question A to get unstuck -- "you really need to figure out A fast".

[x] children learn concepts, such as "bucket", in very few number of interactions (6 times in their childhood), but the interaction is expansive, consisting of parent playing with the child with the bucket, using it, seeing it at different angles. about 30 minutes of interaction, very rich interactions. the child drives the learning process, manipulating the bucket, seeing it at different angles, and ask questions.

[x] fuzzing programs to test compilers is a good idea. LLM can generate programs, correct or incorrect, to stress test a compiler to see if they are compiled right. the correctness of these programs do not matter.

[x] jesse mu : to make sure model has good alignment with human, you can just ask it more questions, interact with it further, to see if it is still aligned.

[x] marta : a great way to "measure" which tool is better in an open task (i.e. user do w/e they want) is to give the user a choice of tool, and see which they prefer more.

[x] armando: some abstractions (w.r.t. LLM) are easy to translate and make connection to abstractiosn people use, others are outright impossible. humans have many different ways to use language to achieve the same goal.

doing research (around llm as blackbox) is not a game we (armando's group) wants to play. llm is a steam roller, best not stand too close to it.

[x] it is good to be clear about authorship of the paper _as soon as possible_ so that the first author assumes all responsibilities, i.e. the "catch all exception".

[x] you want to make sure collaboration is in agreement on all levels: why -- why are we doing what we're doing? what -- what we're doing in order to meet the why? how -- the actual details. the agreement needs to be done in this order. make sure the team is in agreement on all levels, in this order. otherwise you can't move forward.

[x] accomplishment is cool. getting things done are cool. "I don't care" is not cool at all, as it doesn't actually make anything.

[x] there is a trade-off of automation and flexibility. typically you choose one or the other, but if you do it right you can do both.

[x] good research address a bottleneck of a community that is current. you want to align this with your own interests.

[x] validity = complexity in the right direction. you want to work on valid problems, not arbitrarily complex problems for no good reason.

[x] I think humans place a disporportional amount of importance on energetic systems, as we are intrinstically energy seeking creatures. this reflects in fictions and politics, where we imagine adversaries and violence as our biggest threats -- someone out there to "get us". but the world is energy starved, and most of threats are the lack of energy, the boring dispassionate threat of coldness and starvation.

[x] The Dialectics of Sketching: to _design_ is to plan for the making of something new.

[x] josh: building collaborations with people you can learn from — not just do good work with, but learn from their approaches to research — is very good.

[x] neural models -- good at bullshit almost right answers better than random. programs -- work tirelessly over large input sizes but brittle. reasoning (symbolic or probablistic) -- exhaustive over small domains and accurate, but unscalable. humans -- can do all 3 of the above if given enough time, but is expensive. we need to combine these things together in a truly collaborative system.

[x] I need to work on having a tighter research statement sooner. my iteration speed on projects is lacking, because I explore too much and don't clamp down soon enough. focus on having a clear statement sooner. having people critique my work before all the details are fleshed out is helpful.

[x] Robert Hawkins: as soon as you have a dictionary it becomes out of date. meanings change over time. I wonder what this has to do with how crappy programming language semantics, and DSL are?

[x] tagging an image, providing a label, providing a caption. these are the bricks of the dataset pyramid. these are very regular in "shape" and easy to "stack". however, more interesting interactions, like the way human teach each other, do not have regular "shapes". they are unique experiences and machines don't know how to aggregate or "stack" them. we need to stack these weird but powerful bricks, build systems that can do that.

[x] pyramids are cool. they're cool because it is a physical accumulator. you can explain what makes a pyramid to anyone, an algorithm about moving rocks and placing them, and _everyone_ can execute this algorithm. this shared problem, everyone contributing to it. a good research statement should strive to be the same. A research direction shall be addative. A good way of being addative is by being measurable (think benchmark and dataset) is good, fields that can be measurable improve faster (sam told me this).

[x] programming system should be viewed as a knowledge accumulator. more people interact, more knowledge accumulated within. much like how a person accumulates knowledge. stackoverflow and github are kinda like this, but not quite there. copilot is even further not there.

[x] wisdom of crowd isn't an aggregation over opinions, that is ungrounded and flaccid. wisdom of crowd is sharing a problem that everyone can agree on is important to solve, that a good solution is hard to find, yet apparent once found (think NP). everyone attempts to solve it in their own way. blast out the search space. more people, more likely to find a good solution. that is true wisdom of the crowd. once a solution is found, everyone benefits.

[x] Gerald Sussman said about code/programs along the line of: I can give up general correctness for ease of use right here and now. It's hard to prove general things, so you make a specialized case. But that is brittle.

[x] LLM will suck at playing 20 questions, as it forces a consistent internal model. It will suck even more at playing [situation puzzles](https://en.wikipedia.org/wiki/Situation_puzzle). This will be a very good turing test. If an LLM can play a situation puzzle with a participant, I'd be very surprised and happy. The hilarious part is for a LLM it is very easy to play the role of the oracle in these games, so you can set this up in a self-play way.

[x] a good way to talk about auto-complete is to have the notion of a past set and a future set. the past set is what you've already given the system, and the system's job is to predict the future set. the past set and future set together is the completed thing.

[x] edge is a cool word. in research, what is your edge over other people? what are something only you can do?

[x] Daniel fried said for auto-complete like code, short time-horizon is good, i.e. predict the next thing instead of predicting everything at once. this is intuitive.

[x] abduction -- spinning up a DSL "on the fly" for a particular task is a very important problem. it seems human does this, and it solves the "no DSL closure" issue.

[x] learning via associations is essentially learning with redundancy. two things `A, B`, are given to you, you make some kind of relationship between them (think conditional probability `P(B|A))`. this relationship can be used to recover (partially) one in the absence of another, i.e. redundancy.

[x] beilei on branding: say you're person A. how would someone else, B, explain your work to C? this explanation is basically your brand.

[x] someone in design probably: "whenever someone is using a tool, they're having a conversation with its creator."

[x] josh : "are you evaluating it or you're just guessing?" "is this effect big or small?"

[x] dataset can be same or different. analysis can be same or different. analysis = same dataset, same analysis; replication = different dataset, same analysis; robust is same dataset, different analysis; generalizable is different dataset, different analysis.

[x] leo quoting tao: "once you have the right solution, making it work on something impressive does not scale linearly with efforts." thus, with the right idea, you can push it to something more impressive.

[x] kevin : "interpretable equations have 'units', i.e. F = Gm1m2/rr, whereas the 'equations' implemented in a neural network have no 'units'.

[x] robert : "convention exists in a community, but everyone's experience is personal"

[x] asolar : people re-use primitives in a language because they can be manipulated and understood easily. however, library is essentially a new language and require a lot of effort to learn, thus, people re-implement. loops and if-then-else are pretty common across languages, but the more specific constructs are obscure.

[x] j.carrol on 'naming and cescribing in social communications': 1) the distiction between "name" and "description" is not clear at all, it is a gradient. 2) people reach a "name" through coordination and negotiation, in absence of observation of these processes, a name is unintelligible. 3) the shortening from description to name depends on situation, sometimes it shortens slowly when the set of distractors is difficult, and quickly if only few distractors are present. self note: compare this to programs, where "name" is function-name, and "description" is in a sense a function's body.

[x] josh : "the goal of the abstract is to get the right people interested in reading the paper, but not to overpromise. who should read this paper and why?"

[x] robert : you can give data to psych people in two forms. wide-form, where each user is 1 row cllapsed in a style of json dictionary. long-form, where each unit of analysis is 1 row expanded out (R likes this form more).

[x] marta : when you get data, first thing to do is to do _descriptive statistics_ such as number of participants, average length of descriptions, etc.

[x] josh : "the most striking thing about our data is ...". "this quantitative result can _carry_ the paper alone.

[x] josh : have a hypothesis before going out to collect data, think deeply before going yolo.

[x] in collaboration it is helpful to explain straightforwardly what difficulty _you_ currently have, so everyone is on the same page. also asks other to explain theirs. share these difficulties, share these "cost functions" and optimize together.

[x] alex bishara : if you want to amplify a direction of research, it should be done in a manner that is irrelevant if people continue to work with you or not. ultimately they should be able to go in that direction independently.

[x] robert hawkins : the other approaches are not competition, but a "foil" which we can use to contextualize our own works.

[x] josh : what is the question? how should we answer them? in another words, can you show me a plot, and how the plot turned up will answer the question one way or another?

[x] "hold strong opinions loosely"